{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMRFE9q4Zamj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alb6ziyMjgm1",
        "outputId": "2d37af95-556f-49bc-bf8d-ad5b84ac0f86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/drive/MyDrive/Project Work/dataset images\n",
        "/content/drive/MyDrive/sample_Signature/added dataset\n"
      ],
      "metadata": {
        "id": "KPZNF6Z9aPXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real_path = '/content/drive/MyDrive/Project Work/dataset split/real'\n",
        "forge_path = '/content/drive/MyDrive/Project Work/dataset split/forgery'\n",
        "\n",
        "real_images = []\n",
        "for img_name in os.listdir(real_path):\n",
        "    img = cv2.imread(os.path.join(real_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
        "    real_images.append(img)\n",
        "real_images = np.array(real_images, dtype=object)\n",
        "\n",
        "forge_images = []\n",
        "for img_name in os.listdir(forge_path):\n",
        "    img = cv2.imread(os.path.join(forge_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
        "    forge_images.append(img)\n",
        "forge_images = np.array(forge_images, dtype=object)"
      ],
      "metadata": {
        "id": "gyRZj15UaEQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_labels = np.zeros(real_images.shape[0])\n",
        "forge_labels = np.ones(forge_images.shape[0])\n",
        "\n",
        "X = np.concatenate((real_images, forge_images), axis=0)\n",
        "y = np.concatenate((real_labels, forge_labels), axis=0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "3wXYr24saaPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# import numpy as np\n",
        "\n",
        "# # load the dataset\n",
        "# real_path = '/content/drive/MyDrive/Project Work/dataset images/Testing/original'\n",
        "# forge_path = '/content/drive/MyDrive/Project Work/dataset images/Testing/Fraud'\n",
        "\n",
        "# # set the image size to 128x128\n",
        "# img_size = (128, 128)\n",
        "\n",
        "# real_images = []\n",
        "# for img_name in os.listdir(real_path):\n",
        "#     img = cv2.imread(os.path.join(real_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
        "#     img = cv2.resize(img, img_size)\n",
        "#     real_images.append(img)\n",
        "# real_images = np.array(real_images)\n",
        "\n",
        "# forge_images = []\n",
        "# for img_name in os.listdir(forge_path):\n",
        "#     img = cv2.imread(os.path.join(forge_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
        "#     img = cv2.resize(img, img_size)\n",
        "#     forge_images.append(img)\n",
        "# forge_images = np.array(forge_images)\n",
        "\n",
        "# # normalize the data\n",
        "# real_images = real_images.astype('float32') / 255.0\n",
        "# forge_images = forge_images.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "lGxGaQ5Pajc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load the dataset\n",
        "real_path = '/content/drive/MyDrive/Project Work/dataset split/real'\n",
        "forge_path = '/content/drive/MyDrive/Project Work/dataset split/forgery'\n",
        "\n",
        "# set the image size to 128x128\n",
        "img_size = (128, 128)\n",
        "\n",
        "real_images = []\n",
        "for img_name in os.listdir(real_path):\n",
        "    img = cv2.imread(os.path.join(real_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, img_size)\n",
        "    real_images.append(img)\n",
        "real_images = np.array(real_images)\n",
        "\n",
        "forge_images = []\n",
        "for img_name in os.listdir(forge_path):\n",
        "    img = cv2.imread(os.path.join(forge_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, img_size)\n",
        "    forge_images.append(img)\n",
        "forge_images = np.array(forge_images)\n",
        "\n",
        "# normalize the data\n",
        "real_images = real_images.astype('float32') / 255.0\n",
        "forge_images = forge_images.astype('float32') / 255.0\n",
        "\n",
        "# create labels for the dataset: 0 for real images, 1 for forged images\n",
        "real_labels = np.zeros(len(real_images))\n",
        "forge_labels = np.ones(len(forge_images))\n",
        "\n",
        "# concatenate real and forged images and labels\n",
        "X = np.concatenate((real_images, forge_images), axis=0)\n",
        "y = np.concatenate((real_labels, forge_labels), axis=0)\n",
        "\n",
        "# split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the distribution of real and forged images in the test set\n",
        "print(\"Test set distribution:\")\n",
        "print(\"Real images in test set:\", np.sum(y_test == 0))\n",
        "print(\"Forged images in test set:\", np.sum(y_test == 1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBQ0Tgfu1PaG",
        "outputId": "a16c77b4-e224-4e3c-f639-074a94873977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set distribution:\n",
            "Real images in test set: 216\n",
            "Forged images in test set: 215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "num_real_images = len(real_images)\n",
        "num_forge_images = len(forge_images)\n",
        "\n",
        "# Create labels for the real and forged signatures\n",
        "real_labels = np.zeros(num_real_images, dtype=int)\n",
        "forge_labels = np.ones(num_forge_images, dtype=int)\n",
        "\n",
        "# Concatenate the real and forged images and labels\n",
        "X = np.concatenate((real_images, forge_images), axis=0)\n",
        "y = np.concatenate((real_labels, forge_labels), axis=0)"
      ],
      "metadata": {
        "id": "OJiAkLPIayQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# create dummy data\n",
        "X_train = np.random.rand(40, 128, 128)\n",
        "\n",
        "# add another dimension to the array\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "\n",
        "# reshape the array\n",
        "X_train = X_train.reshape(X_train.shape[0], 128, 128, 1)\n",
        "\n",
        "print(X_train.shape)  # output: (40, 128, 128, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2Icr9kWa1A8",
        "outputId": "bcd98298-c05f-4a4f-80a2-ba3cd570ee0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 128, 128, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# create dummy data\n",
        "X_test = np.random.rand(40, 128, 128)\n",
        "\n",
        "# add another dimension to the array\n",
        "X_test = np.expand_dims(X_test, axis=-1)\n",
        "\n",
        "# reshape the array\n",
        "X_test = X_train.reshape(X_test.shape[0], 128, 128, 1)\n",
        "\n",
        "print(X_train.shape)  # output: (40, 128, 128, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvsFr38Va4L0",
        "outputId": "6a7f3cdd-01d5-48bc-9cd9-8e8248416a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 128, 128, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add a convolutional layer\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(128, 128, 1)))\n",
        "\n",
        "# Add a max pooling layer\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Add another convolutional layer\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "# Add another max pooling layer\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Flatten the output from the convolutional layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a fully connected layer with 128 neurons and a relu activation function\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "\n",
        "# Add a dropout layer to reduce overfitting\n",
        "model.add(Dropout(rate=0.5))\n",
        "\n",
        "# Add the output layer with a sigmoid activation function\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Print a summary of the model architecture\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yzvqa8mPa7_l",
        "outputId": "64fc97d6-f2c5-4e50-929f-84af9ed3b58d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 126, 126, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 63, 63, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 57600)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               7372928   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7391873 (28.20 MB)\n",
            "Trainable params: 7391873 (28.20 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXfC_BSCbDk8",
        "outputId": "6849578c-4f00-414a-bd65-6010ec48d951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "54/54 [==============================] - 45s 787ms/step - loss: 0.0298 - accuracy: 0.9936 - val_loss: 0.6422 - val_accuracy: 0.8585\n",
            "Epoch 2/50\n",
            "54/54 [==============================] - 42s 774ms/step - loss: 0.0399 - accuracy: 0.9896 - val_loss: 0.6869 - val_accuracy: 0.8376\n",
            "Epoch 3/50\n",
            "54/54 [==============================] - 41s 753ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.6142 - val_accuracy: 0.8654\n",
            "Epoch 4/50\n",
            "54/54 [==============================] - 39s 719ms/step - loss: 0.0094 - accuracy: 0.9977 - val_loss: 0.5786 - val_accuracy: 0.8724\n",
            "Epoch 5/50\n",
            "54/54 [==============================] - 40s 727ms/step - loss: 0.0150 - accuracy: 0.9959 - val_loss: 0.6131 - val_accuracy: 0.8724\n",
            "Epoch 6/50\n",
            "54/54 [==============================] - 40s 747ms/step - loss: 0.0426 - accuracy: 0.9890 - val_loss: 0.6402 - val_accuracy: 0.8561\n",
            "Epoch 7/50\n",
            "54/54 [==============================] - 40s 751ms/step - loss: 0.0148 - accuracy: 0.9965 - val_loss: 0.5779 - val_accuracy: 0.8677\n",
            "Epoch 8/50\n",
            "54/54 [==============================] - 41s 766ms/step - loss: 0.0060 - accuracy: 0.9994 - val_loss: 0.7376 - val_accuracy: 0.8585\n",
            "Epoch 9/50\n",
            "54/54 [==============================] - 40s 751ms/step - loss: 0.0277 - accuracy: 0.9936 - val_loss: 0.5206 - val_accuracy: 0.8654\n",
            "Epoch 10/50\n",
            "54/54 [==============================] - 40s 750ms/step - loss: 0.0080 - accuracy: 0.9994 - val_loss: 0.6376 - val_accuracy: 0.8631\n",
            "Epoch 11/50\n",
            "54/54 [==============================] - 39s 730ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6649 - val_accuracy: 0.8608\n",
            "Epoch 12/50\n",
            "54/54 [==============================] - 40s 734ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.6862 - val_accuracy: 0.8770\n",
            "Epoch 13/50\n",
            "54/54 [==============================] - 41s 756ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.9725 - val_accuracy: 0.8469\n",
            "Epoch 14/50\n",
            "54/54 [==============================] - 41s 757ms/step - loss: 0.0192 - accuracy: 0.9965 - val_loss: 0.9900 - val_accuracy: 0.8283\n",
            "Epoch 15/50\n",
            "54/54 [==============================] - 40s 737ms/step - loss: 0.0394 - accuracy: 0.9896 - val_loss: 0.9992 - val_accuracy: 0.8445\n",
            "Epoch 16/50\n",
            "54/54 [==============================] - 40s 750ms/step - loss: 0.0255 - accuracy: 0.9919 - val_loss: 0.8302 - val_accuracy: 0.8237\n",
            "Epoch 17/50\n",
            "54/54 [==============================] - 42s 779ms/step - loss: 0.0088 - accuracy: 0.9988 - val_loss: 0.6251 - val_accuracy: 0.8770\n",
            "Epoch 18/50\n",
            "54/54 [==============================] - 41s 753ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6723 - val_accuracy: 0.8677\n",
            "Epoch 19/50\n",
            "54/54 [==============================] - 39s 726ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6956 - val_accuracy: 0.8724\n",
            "Epoch 20/50\n",
            "54/54 [==============================] - 41s 747ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6816 - val_accuracy: 0.8886\n",
            "Epoch 21/50\n",
            "54/54 [==============================] - 40s 746ms/step - loss: 9.9602e-04 - accuracy: 1.0000 - val_loss: 0.7840 - val_accuracy: 0.8724\n",
            "Epoch 22/50\n",
            "54/54 [==============================] - 41s 754ms/step - loss: 9.7060e-04 - accuracy: 1.0000 - val_loss: 0.7991 - val_accuracy: 0.8701\n",
            "Epoch 23/50\n",
            "54/54 [==============================] - 40s 750ms/step - loss: 8.1784e-04 - accuracy: 1.0000 - val_loss: 0.8009 - val_accuracy: 0.8770\n",
            "Epoch 24/50\n",
            "54/54 [==============================] - 41s 762ms/step - loss: 8.6286e-04 - accuracy: 1.0000 - val_loss: 0.8255 - val_accuracy: 0.8794\n",
            "Epoch 25/50\n",
            "54/54 [==============================] - 40s 747ms/step - loss: 8.5762e-04 - accuracy: 1.0000 - val_loss: 0.8056 - val_accuracy: 0.8840\n",
            "Epoch 26/50\n",
            "54/54 [==============================] - 42s 785ms/step - loss: 0.0107 - accuracy: 0.9977 - val_loss: 0.8458 - val_accuracy: 0.8422\n",
            "Epoch 27/50\n",
            "54/54 [==============================] - 41s 761ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8162 - val_accuracy: 0.8794\n",
            "Epoch 28/50\n",
            "54/54 [==============================] - 40s 744ms/step - loss: 9.0359e-04 - accuracy: 1.0000 - val_loss: 0.8535 - val_accuracy: 0.8770\n",
            "Epoch 29/50\n",
            "54/54 [==============================] - 40s 732ms/step - loss: 9.3847e-04 - accuracy: 1.0000 - val_loss: 0.7406 - val_accuracy: 0.8886\n",
            "Epoch 30/50\n",
            "54/54 [==============================] - 40s 743ms/step - loss: 8.1864e-04 - accuracy: 1.0000 - val_loss: 0.7824 - val_accuracy: 0.8840\n",
            "Epoch 31/50\n",
            "54/54 [==============================] - 40s 748ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.8757 - val_accuracy: 0.8654\n",
            "Epoch 32/50\n",
            "54/54 [==============================] - 41s 762ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.7559 - val_accuracy: 0.8701\n",
            "Epoch 33/50\n",
            "54/54 [==============================] - 40s 750ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7640 - val_accuracy: 0.8817\n",
            "Epoch 34/50\n",
            "54/54 [==============================] - 42s 784ms/step - loss: 7.8870e-04 - accuracy: 1.0000 - val_loss: 0.8209 - val_accuracy: 0.8840\n",
            "Epoch 35/50\n",
            "54/54 [==============================] - 42s 774ms/step - loss: 0.0076 - accuracy: 0.9965 - val_loss: 0.7480 - val_accuracy: 0.8445\n",
            "Epoch 36/50\n",
            "54/54 [==============================] - 42s 777ms/step - loss: 0.0266 - accuracy: 0.9896 - val_loss: 0.5921 - val_accuracy: 0.8677\n",
            "Epoch 37/50\n",
            "54/54 [==============================] - 43s 793ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.7598 - val_accuracy: 0.8701\n",
            "Epoch 38/50\n",
            "54/54 [==============================] - 41s 753ms/step - loss: 0.0053 - accuracy: 0.9977 - val_loss: 0.8054 - val_accuracy: 0.8654\n",
            "Epoch 39/50\n",
            "54/54 [==============================] - 42s 786ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8126 - val_accuracy: 0.8701\n",
            "Epoch 40/50\n",
            "54/54 [==============================] - 40s 751ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.6211 - val_accuracy: 0.8654\n",
            "Epoch 41/50\n",
            "54/54 [==============================] - 40s 731ms/step - loss: 0.0234 - accuracy: 0.9930 - val_loss: 0.7547 - val_accuracy: 0.8445\n",
            "Epoch 42/50\n",
            "54/54 [==============================] - 40s 728ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.7463 - val_accuracy: 0.8770\n",
            "Epoch 43/50\n",
            "54/54 [==============================] - 41s 766ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8687 - val_accuracy: 0.8538\n",
            "Epoch 44/50\n",
            "54/54 [==============================] - 41s 767ms/step - loss: 7.8815e-04 - accuracy: 1.0000 - val_loss: 0.7874 - val_accuracy: 0.8840\n",
            "Epoch 45/50\n",
            "54/54 [==============================] - 41s 755ms/step - loss: 7.9994e-04 - accuracy: 1.0000 - val_loss: 0.8026 - val_accuracy: 0.8863\n",
            "Epoch 46/50\n",
            "54/54 [==============================] - 41s 764ms/step - loss: 4.3545e-04 - accuracy: 1.0000 - val_loss: 0.8894 - val_accuracy: 0.8770\n",
            "Epoch 47/50\n",
            "54/54 [==============================] - 40s 746ms/step - loss: 4.4712e-04 - accuracy: 1.0000 - val_loss: 0.8178 - val_accuracy: 0.8817\n",
            "Epoch 48/50\n",
            "54/54 [==============================] - 40s 736ms/step - loss: 7.4896e-04 - accuracy: 1.0000 - val_loss: 0.8017 - val_accuracy: 0.8910\n",
            "Epoch 49/50\n",
            "54/54 [==============================] - 40s 737ms/step - loss: 3.4329e-04 - accuracy: 1.0000 - val_loss: 0.8245 - val_accuracy: 0.8933\n",
            "Epoch 50/50\n",
            "54/54 [==============================] - 41s 765ms/step - loss: 3.0407e-04 - accuracy: 1.0000 - val_loss: 0.8149 - val_accuracy: 0.8956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy:\", test_acc)\n",
        "print(\"Test loss:\", test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzTh__CMbIBj",
        "outputId": "cfa17d94-af9c-471a-dd37-6c9dee35fa11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 2s 165ms/step - loss: 0.8149 - accuracy: 0.8956\n",
            "Test accuracy: 0.895591676235199\n",
            "Test loss: 0.8149474263191223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a signature image\n",
        "# You can change the image path and check if it is forged or real\n",
        "img = cv2.imread('/content/drive/MyDrive/Project Work/dataset split/forgery/002_forg_07.png', cv2.IMREAD_GRAYSCALE)\n",
        "img = cv2.resize(img, (128, 128))\n",
        "img = np.array(img).reshape(1, 128, 128, 1) / 255.0\n",
        "\n",
        "# Predict the class of the signature image\n",
        "prediction = model.predict(img)\n",
        "print(prediction)\n",
        "\n",
        "if prediction < 0.5:\n",
        "    print(\"The signature is real.\")\n",
        "else:\n",
        "    print(\"The signature is forged.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCBt1W7obH7t",
        "outputId": "a8098559-9034-4b50-c121-ded2e4a63237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n",
            "[[0.9999958]]\n",
            "The signature is forged.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iqGllwbExpb8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}